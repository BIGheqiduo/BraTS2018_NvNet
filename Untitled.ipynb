{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIABLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DownSampling(nn.Module):\n",
    "    # 3x3x3 convolution,1 padding as default\n",
    "    def __init__(self, inChans, outChans, stride=2, kernel_size=3, padding=1):\n",
    "        super(DownSampling, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, \n",
    "                     out_channels=outChans, \n",
    "                     kernel_size=kernel_size, \n",
    "                     stride=stride,\n",
    "                     padding=padding,\n",
    "                     bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, inChans, outChans, stride=1, num_groups=4, activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        if normalizaiton == \"group_normalization\":\n",
    "            self.norm1 = nn.GroupNorm(num_groups=num_groups, num_channels=inChans)\n",
    "            self.norm2 = nn.GroupNorm(num_groups=num_groups, num_channels=inChans)\n",
    "        if activation == \"relu\":\n",
    "            self.actv1 = nn.ReLU(inplace=True)\n",
    "            self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1, stride=stride)\n",
    "        self.conv2 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1, stride=stride)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.norm1(x)\n",
    "        out = self.actv1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.actv2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out += residual\n",
    "        return out\n",
    "    \n",
    "class LinearUpSampling(nn.Module):\n",
    "    def __init__(self, inChans, outChans, mode=\"trilinear\", align_corners=True):\n",
    "        super(LinearUpSampling, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1)\n",
    "        scale_factor = inChans / outChans\n",
    "        self.up1 = nn.Upsample(scale_factor=scale_factor,mode=mode, align_corners=align_corners)\n",
    "        self.conv2 = nn.Conv3d(in_channels=2*outChans, out_channels=outChans, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x, skipx):\n",
    "        out = self.conv1(x)\n",
    "        out = self.up1(out)\n",
    "        out = torch.cat((out, skipx), 1)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, inChans, outChans, stride=1, num_groups=4, activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        if normalizaiton == \"group_normalization\":\n",
    "            self.norm1 = nn.GroupNorm(num_groups=num_groups, num_channels=outChans)\n",
    "            self.norm2 = nn.GroupNorm(num_groups=num_groups, num_channels=outChans)\n",
    "        if activation == \"relu\":\n",
    "            self.actv1 = nn.ReLU(inplace=True)\n",
    "            self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1, stride=stride)\n",
    "        self.conv2 = nn.Conv3d(in_channels=outChans, out_channels=outChans, kernel_size=1, stride=stride)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.norm1(x)\n",
    "        out = self.actv1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.actv2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out += residual\n",
    "        return out\n",
    "    \n",
    "class OutputTransition(nn.Module):\n",
    "    def __init__(self, inChans, outChans):\n",
    "        super(OutputTransition, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1)\n",
    "        self.actv1 = F.sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.actv1(self.conv1(x))\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, inChans):\n",
    "        super(VAE, self).__init__()\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "class NvNet(nn.Module):\n",
    "    def __init__(self, inChans=4, activation=\"relu\", normalizaiton=\"group_normalization\", mode=\"trilinear\"):\n",
    "        super(NvNet, self).__init__()\n",
    "        self.in_conv0 = DownSampling(inChans=inChans, outChans=32, kernel_size=1, stride=1, padding=0)\n",
    "        self.en_block0 = EncoderBlock(32, 32, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_down1 = DownSampling(32, 64)\n",
    "        self.en_block1_0 = EncoderBlock(64, 64, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_block1_1 = EncoderBlock(64, 64, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_down2 = DownSampling(64, 128)\n",
    "        self.en_block2_0 = EncoderBlock(128, 128, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_block2_1 = EncoderBlock(128, 128, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_down3 = DownSampling(128, 256)\n",
    "        self.en_block3_0 = EncoderBlock(256, 256, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_block3_1 = EncoderBlock(256, 256, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_block3_2 = EncoderBlock(256, 256, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.en_block3_3 = EncoderBlock(256, 256, activation=activation, normalizaiton=normalizaiton)\n",
    "        \n",
    "        self.de_up2 =  LinearUpSampling(256, 128, mode=mode)\n",
    "        self.de_block2 = DecoderBlock(128, 128, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.de_up1 =  LinearUpSampling(128, 64, mode=mode)\n",
    "        self.de_block1 = DecoderBlock(64, 64, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.de_up0 =  LinearUpSampling(64, 32, mode=mode)\n",
    "        self.de_block0 = DecoderBlock(32, 32, activation=activation, normalizaiton=normalizaiton)\n",
    "        self.de_end = OutputTransition(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_init = self.in_conv0(x)\n",
    "        out_en0 = self.en_block0(out_init)\n",
    "        out_en1 = self.en_block1_1(self.en_block1_0(self.en_down1(out_en0))) \n",
    "        out_en2 = self.en_block2_1(self.en_block2_0(self.en_down2(out_en1)))\n",
    "        out_en3 = self.en_block3_3(\n",
    "            self.en_block3_2(\n",
    "                self.en_block3_1(\n",
    "                    self.en_block3_0(\n",
    "                        self.en_down3(out_en2)))))\n",
    "        out_de2 = self.de_block2(self.de_up2(out_en3, out_en2))\n",
    "        out_de1 = self.de_block1(self.de_up1(out_de2, out_en1))\n",
    "        out_de0 = self.de_block0(self.de_up0(out_de1, out_en0))\n",
    "        \n",
    "        out_end = self.de_end(out_de0)\n",
    "\n",
    "        return out_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_NvNet = NvNet()\n",
    "# print(list(test_NvNet.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 128])\n",
      "torch.Size([1, 1, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "test_NvNet = test_NvNet.cuda(1)\n",
    "x = torch.randn(1,4,128,128,128).cuda(1)\n",
    "out = test_NvNet(x)\n",
    "# print(out)\n",
    "print(x.size())\n",
    "print(out.size())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones((3,5), device=device)  # directly create a tensor on GPU\n",
    "    print(y)\n",
    "    print(y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tmp_block(nn.Module):\n",
    "    def __init__(self, inChans, outChans,stride1=2, stride2=1,activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
    "        super(tmp_block, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=3, stride=stride1, padding=1)\n",
    "        if normalizaiton == \"group_normalization\":\n",
    "            self.norm1 = nn.GroupNorm(num_groups=8, num_channels=outChans)\n",
    "            self.norm2 = nn.GroupNorm(num_groups=8, num_channels=outChans)\n",
    "        if activation == \"relu\":\n",
    "            self.actv1 = nn.ReLU(inplace=True)\n",
    "            self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(in_channels=outChans, out_channels=outChans, kernel_size=1, stride=stride2)\n",
    "        self.conv3 = nn.Conv3d(in_channels=outChans, out_channels=outChans, kernel_size=1, stride=stride2)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        residual = out\n",
    "        \n",
    "        out = self.norm1(out)\n",
    "        out = self.actv1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.actv2(out)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_b = tmp_block(32, 64)\n",
    "print(tmp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 32, 160, 192, 128).cuda(1)\n",
    "# print(input)\n",
    "out = tmp_b(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input.size())\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
